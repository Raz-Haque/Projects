# -*- coding: utf-8 -*-
"""Breast Cancer ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQx2rWc9BKGgG2A_5K6c80ndaoT9QZs8
"""

import pandas as pd
#Load data and into a dataframe
Breast_cancer_data = pd.read_csv("2025_BUIS008W.3 Coursework Dataset (1).csv")
display(Breast_cancer_data.head())
display(Breast_cancer_data.tail())

#Removing chosen dropped variables
Retain_BC_data = Breast_cancer_data.drop(columns=["Patient_ID", "Month_of_Birth", "Occupation", "Survival_Months"])
display(Retain_BC_data.head())

#Summary on dataset
Retain_BC_data.info()

#Descriptive stats
Retain_BC_data.describe()

import seaborn as sns
import matplotlib.pyplot as plt
#Plotting target variable distribution
sns.countplot(x="Mortality_Status", data=Retain_BC_data)
plt.title("Target Variable Distribution")
plt.xlabel("Mortality Status")
plt.ylabel("Count")
plt.show()

#Identifying missing values
Retain_BC_data.isnull().sum()
Retain_BC_data.isnull().sum()/len(Retain_BC_data)*100

# Filling missing values
Retain_BC_data['Age'] = Retain_BC_data['Age']. fillna(Retain_BC_data['Age'].median())
Retain_BC_data['Sex'] = Retain_BC_data['Sex']. fillna(Retain_BC_data['Sex'].mode()[0])
Retain_BC_data['Tumor_Size'] = Retain_BC_data['Tumor_Size']. fillna(Retain_BC_data['Tumor_Size'].mean())
Retain_BC_data['Regional_Node_Examined'] = Retain_BC_data['Regional_Node_Examined']. fillna(Retain_BC_data['Regional_Node_Examined'].median())
Retain_BC_data.isnull().sum()

#Remove Case sensitivity and fill blankspaces for target variable
Retain_BC_data['Mortality_Status'] = Retain_BC_data[ 'Mortality_Status']. str.strip().str.capitalize()

#Plot Target variable distribution again
sns.countplot(x="Mortality_Status", data=Retain_BC_data)
plt.title("Target Variable Distribution")
plt.xlabel("Mortality Status")
plt.ylabel("Count")
plt.show()

#Plot count for 'Sex' variable to find unique entries
Retain_BC_data['Sex'].value_counts(dropna=False)

Retain_BC_data[['A_Stage']].value_counts(dropna=False)

#Check all categorical variables for inconsistent entries
Retain_BC_data[['T_Stage', 'N_Stage', '6th_Stage', 'Differentiated', 'A_Stage','Estrogen_Status','Progesterone_Status']].value_counts(dropna=False)

#drop the variable of sex
Retain_BC_data.drop(columns=['Sex'], inplace=True)

#Show number of rows and variables to help with identfying what rows to drop
Retain_BC_data.shape
#Find extreme Age values and then remove
corrupt_age_indices = Retain_BC_data[(Retain_BC_data['Age']>110) | (Retain_BC_data['Age']<0) ].index
Retain_BC_data.drop(corrupt_age_indices, inplace=True)
#check for confirmation
Retain_BC_data.describe()

#identify and then remove any negative tumour size values
corrupt_tumor_size_indices = Retain_BC_data[Retain_BC_data['Tumor_Size']<0].index
Retain_BC_data.drop(corrupt_tumor_size_indices, inplace=True)
#check for confirmation
Retain_BC_data.describe()
Retain_BC_data.to_csv('Cleaned_BC_Data.csv', index=False)

Retain_BC_data=Retain_BC_data.rename({'Reginol_Node_Positive':'Regional_Node_Positive'}, axis=1)

Retain_BC_data.head()

#Identify and group variables for scaling
scaling_variables = Retain_BC_data.filter(["Age", "Tumor_Size", "Regional_Node_Examined", "Regional_Node_Positive"])
scaling_variables.describe()

#Import class for minmaxscaler
from sklearn.preprocessing import MinMaxScaler
mms= MinMaxScaler()
#Apply MinMaxScaler to scaling variables.
scaling_variables_mms= mms.fit_transform(scaling_variables)
scaling_variables_mms

#converts from array to dataset
scaling_variables_mms_df = pd.DataFrame(scaling_variables_mms, columns=scaling_variables.columns)
scaling_variables_mms_df.head()
scaling_variables_mms_df.describe()

#Add to scaled variables original dataset
Retain_BC_data[['Age', 'Tumor_Size', 'Regional_Node_Examined', 'Regional_Node_Positive']] = scaling_variables_mms_df
Retain_BC_data.head()
Retain_BC_data.to_csv('BC_Data_with_scaledVARs.csv', index=False)

#import class
import pandas as pd
#Load updated dataset into notebook
BC_data = pd.read_csv("BC_Data_with_scaledVARs.csv")
#Define x and y
x = BC_data[['Age','T_Stage','N_Stage','6th_Stage','Differentiated','Grade','A_Stage','Tumor_Size','Estrogen_Status', 'Regional_Node_Examined','Regional_Node_Positive']]
y= BC_data['Mortality_Status']
x.info()
print(x.shape)

#encrypting non-numeric x variables
x1= pd.get_dummies(x,drop_first=True)
#Remove NAN values
#Get rid of null values added from encrypting
x1.dropna(inplace=True)
y=y.loc[x1.index]
x1.head()

#Set train/test split using scikit-learn for binary log data
from sklearn.model_selection import train_test_split
x1_train, x1_test, y_train, y_test = train_test_split(x1, y, test_size=0.3, random_state=42, stratify=y)

#Demonstration of repatability of train/test split.
#Set train/test split using scikit-learn
from sklearn.model_selection import train_test_split
x1_train, x1_test, y_train, y_test = train_test_split(x1, y, test_size=0.3, random_state=42, stratify=y)
#Summarise first five rows
print(x1_train.head())
#split  again (should see same split)
x1_train, x1_test, y_train, y_test = train_test_split(x1, y, test_size=0.3, random_state=42, stratify=y)
#summarise first five rows again
#Set train/test split using scikit-learn
print(x1_train.head())

#output showing ratio of mortality status same for test and train
print(y_train.value_counts(normalize=True))
print(y_test.value_counts(normalize=True))

#Instantiate the model using scikit-learn for logistic regression
#Import class
from sklearn.linear_model import LogisticRegression
#instantiate model (default parameters)
logreg = LogisticRegression()
logreg.fit(x1_train, y_train)
y_pred= logreg.predict(x1_test)

#Get classification report
#Import class for scikit-learn
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred, target_names=['Alive', 'Dead']))

#evaluating model
#import accuracy score from scikit-learn
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test,y_pred)
print(accuracy)
#import metrics class
from sklearn import metrics
#print confusion matrix
log_cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
print(log_cnf_matrix)

#Visualising confusion matrix
#upgrade scikitlearn
!pip install -- upgrade scikit-learn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
cm_visual= confusion_matrix(y_test, y_pred, labels=logreg.classes_)
disp= ConfusionMatrixDisplay(cm_visual, display_labels=logreg.classes_)
disp.plot()

#Receiver Operating Characteristic(ROC) curve visual
#import class
from sklearn.metrics import RocCurveDisplay
logreg = RocCurveDisplay.from_estimator(logreg, x1_test, y_test)

#Define x and y for knn model
x2= x1
y2= y

#Set train/test split
from sklearn.model_selection import train_test_split
x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.3, random_state=42, stratify=y)

#import class for K nearest neigbour model
from sklearn.neighbors import KNeighborsClassifier
#Create KNN classifier
knn= KNeighborsClassifier(n_neighbors = 3)
#Fit classifier to data
knn.fit(x2_train, y2_train)
y2_pred= knn.predict(x2_test)

#Get classification report
#Import class for scikit-learn
from sklearn.metrics import classification_report
print(classification_report(y2_test, y2_pred, target_names=['Alive', 'Dead']))

#evaluating model
#import accuracy score from scikit-learn
from sklearn.metrics import accuracy_score
accuracy_KNN = accuracy_score(y2_test,y2_pred)
print(accuracy_KNN)
#import metrics class
from sklearn import metrics
#print confusion matrix
KNN_cnf_matrix = metrics.confusion_matrix(y2_test, y2_pred)
print(KNN_cnf_matrix)

#Building confusion Matrix visualisation
#upgrade scikitlearn
!pip install -- upgrade scikit-learn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
knn_cm_visual= confusion_matrix(y2_test, y2_pred, labels=knn.classes_)
disp2= ConfusionMatrixDisplay(knn_cm_visual, display_labels=knn.classes_)
disp2.plot()

#Receiver Operating Characteristic(ROC) curve visual
#import class
from sklearn.metrics import RocCurveDisplay
knn_ROC = RocCurveDisplay.from_estimator(knn, x2_test, y2_test)

#pre-processing for NB model
y_NBvalues= [1 if Mortality_Status == 'Dead' else 0 for Mortality_Status in y]

#set x and y for NB model
x3= x1
y3= y_NBvalues

#Set train/test split
from sklearn.model_selection import train_test_split
x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.3, random_state=42, stratify=y)

from sklearn.naive_bayes import GaussianNB
#instantiate model (default parameters)
NB = GaussianNB()
NB.fit(x3_train, y3_train)
y3_pred= NB.predict(x3_test)

#Get classification report
#Import class for scikit-learn
from sklearn.metrics import classification_report
print(classification_report(y3_test, y3_pred, target_names=['Alive', 'Dead']))

#Explore accuracy of NB model
print("Naive Bayes score model accuracy is" , NB.score(x3_test, y3_test))

#import metrics class
from sklearn import metrics
#print confusion matrix
NB_cnf_matrix = metrics.confusion_matrix(y3_test, y3_pred)
print(NB_cnf_matrix)

#Visualise Confusion Matrix
#upgrade scikitlearn
!pip install -- upgrade scikit-learn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
NB_cm_visual= confusion_matrix(y3_test, y3_pred, labels=NB.classes_)
disp3= ConfusionMatrixDisplay(NB_cm_visual, display_labels=['Alive','Dead'])
disp3.plot()

#Receiver Operating Characteristic(ROC) curve visual
#import class
from sklearn.metrics import RocCurveDisplay
NB_ROC = RocCurveDisplay.from_estimator(NB, x3_test, y3_test)

#import classes
import numpy as np
from sklearn.model_selection import GridSearchCV
#Create dictionary of all values to test
logreg_tune= LogisticRegression(max_iter=10000)
param_grid = {
    'penalty': ['l1','l2'],
    'C': [0.01,0.1,1,10,100],
    'solver': ['liblinear','lbfgs']}

#use the gridsearch
grid_search = GridSearchCV(logreg_tune, param_grid, cv=5)
#fit to encoded training data
grid_search.fit(x1_train, y_train)

#Print the best parameters
print('the best parameters for logreg are', grid_search.best_params_)

#Create y-pred for confusion matrix
y_pred_tuned = grid_search.predict(x1_test)
#create confusion matrix for tuned model
from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred_tuned))
print(classification_report(y_test, y_pred_tuned))
#get auc-roc statistic
from sklearn.metrics import roc_auc_score
#predicted probs for positive class, needed for auc-roc
y_probability_tuned = grid_search.predict_proba(x1_test)[:,1]
tuned_logreg_aucroc = roc_auc_score(y_test, y_probability_tuned)
print(tuned_logreg_aucroc)

#Confusion matrix for tuned logreg
!pip install -- upgrade scikit-learn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
logregtune_cm_visual= confusion_matrix(y_test, y_pred_tuned, labels=grid_search.best_estimator_.classes_)
disp4= ConfusionMatrixDisplay(logregtune_cm_visual, display_labels=grid_search.best_estimator_.classes_)
disp4.plot()

#Get visual for AUCROC
Logregtuned_AUCROC= RocCurveDisplay.from_estimator(grid_search, x1_test, y_test)

logreg_best = grid_search.best_estimator_

#Initiate the new ensemble model
from sklearn.ensemble import VotingClassifier
#Create dictionary for base learner models (Logreg and NB)
base_learners= [('logreg',logreg_best),('NB', NB)]
#Create voting classifier, inputting model
ensemble_learner =VotingClassifier(base_learners, voting = 'soft')
#Fit model to training data
ensemble_learner.fit(x1_train, y_train)

# Get predicted probabilities for the positive class
y_pred_ensemble = ensemble_learner.predict(x1_test)

#Confusion matrix for ensemble learner
!pip install -- upgrade scikit-learn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
ensemblelearner_cm_visual= confusion_matrix(y_test, y_pred_ensemble, labels=ensemble_learner.classes_)
disp5= ConfusionMatrixDisplay(ensemblelearner_cm_visual, display_labels=ensemble_learner.classes_)
disp5.plot()

#Get values for the used metrics for ensemble model
print(classification_report(y_test, y_pred_ensemble))

#Get visual for AUCROC
Ensemble_learner_AUCROC= RocCurveDisplay.from_estimator(ensemble_learner, x1_test, y_test)

#Task B
#Get data for just patients who did not survive
Retain_BC_data_B = Breast_cancer_data[Breast_cancer_data['Mortality_Status'].str.strip().str.lower() == 'dead']

print(Retain_BC_data_B['Mortality_Status'].unique())

#Retained variables
Retain_BC_data_B = Retain_BC_data_B.drop(columns=['Mortality_Status', 'Patient_ID', 'Month_of_Birth', 'Occupation', 'Sex'])

#Drop variables to create retained dataset for modelling
display(Retain_BC_data_B.head())
Retain_BC_data_B.info()
Retain_BC_data_B.shape

# Filling missing values
Retain_BC_data_B['Age'] = Retain_BC_data_B['Age']. fillna(Retain_BC_data_B['Age'].median())
Retain_BC_data_B['Tumor_Size'] = Retain_BC_data_B['Tumor_Size']. fillna(Retain_BC_data_B['Tumor_Size'].mean())
Retain_BC_data_B['Regional_Node_Examined'] = Retain_BC_data_B['Regional_Node_Examined']. fillna(Retain_BC_data_B['Regional_Node_Examined'].median())
Retain_BC_data_B.isnull().sum()

#Show number of rows and variables to help with identfying what rows to drop
Retain_BC_data_B.shape
#Find extreme Age values and then remove
corrupt_age_indices_B = Retain_BC_data_B[(Retain_BC_data_B['Age']>110) | (Retain_BC_data_B['Age']<0) ].index
Retain_BC_data_B.drop(corrupt_age_indices_B, inplace=True)
#check for confirmation
Retain_BC_data_B.describe()

#identify and then remove any negative tumour size values
corrupt_tumor_size_indices_B = Retain_BC_data_B[Retain_BC_data_B['Tumor_Size']<0].index
Retain_BC_data_B.drop(corrupt_tumor_size_indices_B, inplace=True)
#check for confirmation
Retain_BC_data_B.describe()

Retain_BC_data_B=Retain_BC_data_B.rename({'Reginol_Node_Positive':'Regional_Node_Positive'}, axis=1)

#Identify and group variables for scaling
scaling_variables_B = Retain_BC_data_B.filter(["Age", "Tumor_Size", "Regional_Node_Examined", "Regional_Node_Positive"])
scaling_variables_B.describe()

#Import class for minmaxscaler
from sklearn.preprocessing import MinMaxScaler
mms= MinMaxScaler()
#Apply MinMaxScaler to scaling variables.
scaling_variablesB_mms= mms.fit_transform(scaling_variables_B)
scaling_variablesB_mms

#converts from array to dataset
scaling_variablesB_mms_df = pd.DataFrame(scaling_variablesB_mms, columns=scaling_variables_B.columns)
scaling_variablesB_mms_df.head()
scaling_variablesB_mms_df.describe()

#Add to scaled variables original dataset
Retain_BC_data_B[['Age', 'Tumor_Size', 'Regional_Node_Examined', 'Regional_Node_Positive']] = scaling_variablesB_mms_df
Retain_BC_data_B.head()
Retain_BC_data_B.to_csv('BC_Data_with_scaledVARs_task B.csv', index=False)

import pandas as pd
Retain_BC_data_B.info()
Retain_BC_data_B.shape

#Load necessary libraries
import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn import metrics

#split into feature and target variables
feature_columns_B = ['Age', 'T_Stage', 'N_Stage','6th_Stage','Differentiated','Grade','A_Stage','Tumor_Size','Estrogen_Status', 'Progesterone_Status','Regional_Node_Examined','Regional_Node_Positive']
X_B = Retain_BC_data_B[feature_columns_B]
Y_B= Retain_BC_data_B.Survival_Months

# Encrypting non-numeric feature variables
X_B = pd.get_dummies(X_B, drop_first=True)
#Update feature columsn
feature_columns_B = X_B.columns.tolist()

#Split data into train and test split
X_train_B, X_test_B, Y_train_B, Y_test_B = train_test_split(X_B, Y_B, test_size=0.3, random_state=1)

#Create Decision Tree classifier Object
DTR = DecisionTreeRegressor()
#Train Decision Tree Classifier
DTR = DTR.fit(X_train_B,Y_train_B)
#Predict the response for test dataset
Y_pred_B = DTR.predict(X_test_B)

from sklearn import tree
from matplotlib import pyplot as plt
DT_fig = plt.figure(figsize=(200,200))
DT_Graph = tree.plot_tree(DTR, feature_names=feature_columns_B,filled = True)

#Prune decision tree to 4 levels
DTR_PRUNE= DecisionTreeRegressor(max_depth=4, min_samples_leaf=5, max_leaf_nodes = 10)
DTR_PRUNE = DTR_PRUNE.fit(X_train_B,Y_train_B)
y_pred_pruned = DTR_PRUNE.predict(X_test_B)

from sklearn import tree
from matplotlib import pyplot as plt
DT_Prune_fig = plt.figure(figsize=(15,15))
tree.plot_tree(DTR_PRUNE, feature_names=feature_columns_B,filled = True, max_depth=3)

#Import classes for MSE AND mae AND r squared
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
#Get unpruned metrics
MSE = mean_squared_error(Y_test_B, Y_pred_B)
MAE = mean_absolute_error(Y_test_B, Y_pred_B)
R2 = r2_score(Y_test_B, Y_pred_B)

#Get Pruned metrics
MSE_PRUNE = mean_squared_error(Y_test_B, y_pred_pruned)
MAE_PRUNE = mean_absolute_error(Y_test_B, y_pred_pruned)
R2_PRUNE = r2_score(Y_test_B, y_pred_pruned)

#Print used metrics for Unpruned and Pruned decision trees
print("Unpruned MSE is", MSE)
print("Unpruned MAE is", MAE)
print("Unpruned R2 is", R2)
print("Pruned MSE is", MSE_PRUNE)
print("Pruned MAE is", MAE_PRUNE)
print("Pruned R2 is", R2_PRUNE)